{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Record on Proactive Label Relaxation on Fer2013 DATASET \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Loading dataset from .npy files\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train = np.load('X_train_Fer2013.npy')\n",
    "#X_train_2 = np.load('evae_conditional_fer2013_sample_neutral_sample_neutral_a=0_v1.npy')\n",
    "#X_train_2 = X_train_2.reshape((X_train_2.shape[0], -1))\n",
    "X_test = np.load('X_test_Fer2013.npy')\n",
    "#y_train = np.load('y_train_Fer2013.npy')\n",
    "y_test = np.load('y_test_Fer2013.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Loading crafted soft training labels and tesitng labels \n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "y_test  = to_categorical(y_test)\n",
    "#y_train = to_categorical(y_train)\n",
    "y_train = np.load('proactive_label_fer2013_v7_divide12_bound3.0*6.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0429794 , 0.04216032, 0.74543467, 0.04297165, 0.04265694,\n",
       "       0.04188894, 0.04190807])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## convert image size for CNN \n",
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train= X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, PReLU, Dropout, Dense\n",
    "from keras.layers import Flatten, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model_pr = Sequential()\n",
    "\n",
    "model_pr.add(Conv2D(16, (7, 7), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv1'))\n",
    "model_pr.add(PReLU())\n",
    "model_pr.add(BatchNormalization())\n",
    "model_pr.add(AveragePooling2D(pool_size=(5, 5),strides=(2, 2), padding='same', name = 'block1_pool1'))\n",
    "model_pr.add(Dropout(.5))\n",
    "\n",
    "model_pr.add(Conv2D(32, (5, 5), padding='same', name = 'block2_conv1'))\n",
    "model_pr.add(PReLU())\n",
    "model_pr.add(BatchNormalization())\n",
    "model_pr.add(AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same', name = 'block2_pool1'))\n",
    "model_pr.add(Dropout(.5))\n",
    "\n",
    "model_pr.add(Conv2D(32, (3, 3), padding='same', name = 'block3_conv1'))\n",
    "model_pr.add(PReLU())\n",
    "model_pr.add(BatchNormalization())\n",
    "model_pr.add(AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same', name = 'block3_pool1'))\n",
    "model_pr.add(Dropout(.5))\n",
    "\n",
    "model_pr.add(Flatten())\n",
    "model_pr.add(Dense(512, name = 'fc1'))\n",
    "model_pr.add(PReLU())\n",
    "model_pr.add(Dropout(0.5))\n",
    "model_pr.add(Dense(num_classes))\n",
    "model_pr.add(Activation('softmax', name ='predictions'))\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "#sgd_wn = SGDWithWeightnorm(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_pr.compile(loss = categorical_crossentropy, optimizer = Adam(), metrics = ['accuracy'])\n",
    "\n",
    "# callback history \n",
    "from keras.callbacks import EarlyStopping,TensorBoard,History, ReduceLROnPlateau\n",
    "\n",
    "#earlyStop  = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 0, verbose = 0, mode = 'auto')\n",
    "\n",
    "#tbcallback = TensorBoard(log_dir = './smooth_logs', histogram_freq = 0, write_graph = True, write_images = True)\n",
    "\n",
    "hist_vanilla    = History()\n",
    "\n",
    "rdLR       = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 10, verbose = 0, \n",
    "                              mode = 'auto', min_delta = 0.001, cooldown = 0, min_lr = 0)\n",
    "\n",
    "model_vanilla_callbacks = [hist_vanilla, rdLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/150\n",
      " - 188s - loss: 1.8566 - acc: 0.2875 - val_loss: 1.7303 - val_acc: 0.3168\n",
      "Epoch 2/150\n",
      " - 188s - loss: 1.7311 - acc: 0.3490 - val_loss: 1.7078 - val_acc: 0.3536\n",
      "Epoch 3/150\n",
      " - 189s - loss: 1.6882 - acc: 0.3841 - val_loss: 1.5916 - val_acc: 0.3812\n",
      "Epoch 4/150\n",
      " - 189s - loss: 1.6566 - acc: 0.4012 - val_loss: 1.4843 - val_acc: 0.4366\n",
      "Epoch 5/150\n",
      " - 189s - loss: 1.6301 - acc: 0.4175 - val_loss: 1.4840 - val_acc: 0.4372\n",
      "Epoch 6/150\n",
      " - 190s - loss: 1.6092 - acc: 0.4305 - val_loss: 1.4496 - val_acc: 0.4505\n",
      "Epoch 7/150\n",
      " - 190s - loss: 1.5872 - acc: 0.4431 - val_loss: 1.3833 - val_acc: 0.4765\n",
      "Epoch 8/150\n",
      " - 190s - loss: 1.5682 - acc: 0.4581 - val_loss: 1.4420 - val_acc: 0.4712\n",
      "Epoch 9/150\n",
      " - 190s - loss: 1.5503 - acc: 0.4705 - val_loss: 1.3799 - val_acc: 0.4979\n",
      "Epoch 10/150\n",
      " - 191s - loss: 1.5376 - acc: 0.4750 - val_loss: 1.3422 - val_acc: 0.4909\n",
      "Epoch 11/150\n",
      " - 190s - loss: 1.5197 - acc: 0.4857 - val_loss: 1.3120 - val_acc: 0.5057\n",
      "Epoch 12/150\n",
      " - 190s - loss: 1.5115 - acc: 0.4928 - val_loss: 1.2922 - val_acc: 0.5029\n",
      "Epoch 13/150\n",
      " - 189s - loss: 1.4949 - acc: 0.4989 - val_loss: 1.2940 - val_acc: 0.5121\n",
      "Epoch 14/150\n",
      " - 191s - loss: 1.4863 - acc: 0.5063 - val_loss: 1.3053 - val_acc: 0.5213\n",
      "Epoch 15/150\n",
      " - 190s - loss: 1.4796 - acc: 0.5086 - val_loss: 1.2991 - val_acc: 0.5263\n",
      "Epoch 16/150\n",
      " - 188s - loss: 1.4626 - acc: 0.5196 - val_loss: 1.3005 - val_acc: 0.5124\n",
      "Epoch 17/150\n",
      " - 189s - loss: 1.4581 - acc: 0.5198 - val_loss: 1.2542 - val_acc: 0.5386\n",
      "Epoch 18/150\n",
      " - 189s - loss: 1.4479 - acc: 0.5283 - val_loss: 1.2221 - val_acc: 0.5447\n",
      "Epoch 19/150\n",
      " - 189s - loss: 1.4411 - acc: 0.5328 - val_loss: 1.2703 - val_acc: 0.5612\n",
      "Epoch 20/150\n",
      " - 191s - loss: 1.4347 - acc: 0.5353 - val_loss: 1.2543 - val_acc: 0.5386\n",
      "Epoch 21/150\n",
      " - 191s - loss: 1.4275 - acc: 0.5412 - val_loss: 1.1965 - val_acc: 0.5436\n",
      "Epoch 22/150\n",
      " - 190s - loss: 1.4242 - acc: 0.5431 - val_loss: 1.1974 - val_acc: 0.5606\n",
      "Epoch 23/150\n",
      " - 190s - loss: 1.4164 - acc: 0.5432 - val_loss: 1.2321 - val_acc: 0.5561\n",
      "Epoch 24/150\n",
      " - 190s - loss: 1.4113 - acc: 0.5485 - val_loss: 1.3136 - val_acc: 0.5188\n",
      "Epoch 25/150\n",
      " - 190s - loss: 1.4030 - acc: 0.5535 - val_loss: 1.2290 - val_acc: 0.5548\n",
      "Epoch 26/150\n",
      " - 190s - loss: 1.3971 - acc: 0.5530 - val_loss: 1.2228 - val_acc: 0.5522\n",
      "Epoch 27/150\n",
      " - 191s - loss: 1.3977 - acc: 0.5556 - val_loss: 1.1789 - val_acc: 0.5584\n",
      "Epoch 28/150\n",
      " - 190s - loss: 1.3894 - acc: 0.5595 - val_loss: 1.2047 - val_acc: 0.5592\n",
      "Epoch 29/150\n",
      " - 190s - loss: 1.3848 - acc: 0.5652 - val_loss: 1.2275 - val_acc: 0.5478\n",
      "Epoch 30/150\n",
      " - 191s - loss: 1.3781 - acc: 0.5684 - val_loss: 1.1811 - val_acc: 0.5603\n",
      "Epoch 31/150\n",
      " - 190s - loss: 1.3759 - acc: 0.5673 - val_loss: 1.2031 - val_acc: 0.5712\n",
      "Epoch 32/150\n",
      " - 189s - loss: 1.3680 - acc: 0.5720 - val_loss: 1.1805 - val_acc: 0.5706\n",
      "Epoch 33/150\n",
      " - 190s - loss: 1.3610 - acc: 0.5797 - val_loss: 1.2139 - val_acc: 0.5698\n",
      "Epoch 34/150\n",
      " - 191s - loss: 1.3615 - acc: 0.5754 - val_loss: 1.2083 - val_acc: 0.5751\n",
      "Epoch 35/150\n",
      " - 190s - loss: 1.3559 - acc: 0.5801 - val_loss: 1.1785 - val_acc: 0.5678\n",
      "Epoch 36/150\n",
      " - 190s - loss: 1.3528 - acc: 0.5832 - val_loss: 1.2361 - val_acc: 0.5745\n",
      "Epoch 37/150\n",
      " - 191s - loss: 1.3497 - acc: 0.5814 - val_loss: 1.1583 - val_acc: 0.5759\n",
      "Epoch 38/150\n",
      " - 189s - loss: 1.3392 - acc: 0.5883 - val_loss: 1.2238 - val_acc: 0.5598\n",
      "Epoch 39/150\n",
      " - 190s - loss: 1.3434 - acc: 0.5863 - val_loss: 1.1761 - val_acc: 0.5815\n",
      "Epoch 40/150\n",
      " - 193s - loss: 1.3361 - acc: 0.5912 - val_loss: 1.1875 - val_acc: 0.5623\n",
      "Epoch 41/150\n",
      " - 191s - loss: 1.3366 - acc: 0.5921 - val_loss: 1.2287 - val_acc: 0.5807\n",
      "Epoch 42/150\n",
      " - 191s - loss: 1.3293 - acc: 0.5933 - val_loss: 1.1382 - val_acc: 0.5857\n",
      "Epoch 43/150\n",
      " - 193s - loss: 1.3256 - acc: 0.6004 - val_loss: 1.2226 - val_acc: 0.5609\n",
      "Epoch 44/150\n",
      " - 191s - loss: 1.3271 - acc: 0.5945 - val_loss: 1.1621 - val_acc: 0.5715\n",
      "Epoch 45/150\n",
      " - 195s - loss: 1.3226 - acc: 0.6004 - val_loss: 1.1452 - val_acc: 0.5893\n",
      "Epoch 46/150\n",
      " - 190s - loss: 1.3188 - acc: 0.6008 - val_loss: 1.1482 - val_acc: 0.5862\n",
      "Epoch 47/150\n",
      " - 191s - loss: 1.3182 - acc: 0.5993 - val_loss: 1.1817 - val_acc: 0.5862\n",
      "Epoch 48/150\n",
      " - 254s - loss: 1.3150 - acc: 0.6012 - val_loss: 1.1805 - val_acc: 0.5751\n",
      "Epoch 49/150\n",
      " - 315s - loss: 1.3098 - acc: 0.6060 - val_loss: 1.1800 - val_acc: 0.5834\n",
      "Epoch 50/150\n",
      " - 271s - loss: 1.3087 - acc: 0.6073 - val_loss: 1.1965 - val_acc: 0.5759\n",
      "Epoch 51/150\n",
      " - 247s - loss: 1.3058 - acc: 0.6072 - val_loss: 1.1287 - val_acc: 0.5921\n",
      "Epoch 52/150\n",
      " - 252s - loss: 1.3054 - acc: 0.6094 - val_loss: 1.1657 - val_acc: 0.5924\n",
      "Epoch 53/150\n",
      " - 266s - loss: 1.3075 - acc: 0.6041 - val_loss: 1.1607 - val_acc: 0.5829\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-83b6e9cd90a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_vanilla_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 150 #cease to improve after 50 epoches \n",
    "batch_size = 100\n",
    "\n",
    "model_pr.fit(X_train,y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs = num_epochs,\n",
    "          verbose= 2,\n",
    "          callbacks=model_vanilla_callbacks,\n",
    "          shuffle=True,\n",
    "          validation_data =(X_test,y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_history = hist_vanilla.history\n",
    "\n",
    "#pd.DataFrame(training_history).to_csv('hist_bound_2.5_x7_150epoch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, PReLU, Dropout, Dense\n",
    "from keras.layers import Flatten, Activation,Subtract\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, ReLU\n",
    "from keras.layers import Concatenate\n",
    "from keras import Model\n",
    "from keras.layers import Dot,Multiply,Subtract,Add,BatchNormalization, Average, Maximum\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "input_shape = (48,48,1)\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "x = Input(shape=input_shape, name='input')\n",
    "###  Tryout more variations of initlisation techniques \n",
    "### without any pre-training \n",
    "### without any weight initilaistion \n",
    "\n",
    "##\n",
    "h1 = Conv2D(16, (7, 7), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv1', activation = 'relu')(x)\n",
    "\n",
    "h1 = BatchNormalization()(h1)\n",
    "h1 = AveragePooling2D(pool_size=(5, 5),strides=(2, 2), padding='same')(h1)\n",
    "h1 = Dropout(.5)(h1)\n",
    "\n",
    "##\n",
    "h2 = Conv2D(32, (5, 5), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv2', activation = 'relu')(h1)\n",
    "h2 = BatchNormalization()(h2)\n",
    "h2 = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h2)\n",
    "h2 = Dropout(.5)(h2)\n",
    "\n",
    "##\n",
    "h3 = Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv3', activation = 'relu')(h2)\n",
    "h3 = BatchNormalization()(h3)\n",
    "h3 = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h3)\n",
    "h3 = Dropout(.5)(h3)\n",
    "\n",
    "\n",
    "h3 = Flatten()(h3)\n",
    "h4 = Dense(512, name = 'fc1', activation = 'relu')(h3)\n",
    "h5 = Dropout(0.5)(h4)\n",
    "h5 = BatchNormalization()(h5)\n",
    "h_class = Dense(50, activation = 'relu')(h5)\n",
    "h_class = Dense(7, activation='softmax')(h_class)\n",
    "#h_final.add(Dense(num_classes))\n",
    "#model_p1.add(Activation('softmax', name ='predictions'))\n",
    "\n",
    "'''\n",
    "input_shape_2 = (48*48,)\n",
    "x_2 = Input(shape = input_shape_2)\n",
    "\n",
    "h_2 = Dense(500, activation='relu')(x_2)\n",
    "\n",
    "h_2 = Dense(200,activation='relu')(h_2)\n",
    "\n",
    "h_2 = Dense(50,activation='relu')(h_2)\n",
    "\n",
    "h_2 = BatchNormalization()(h_2)\n",
    "\n",
    "h_final = Subtract()([h_class, h_2])\n",
    "\n",
    "h_final_2 = Add()([h_final, h_class])\n",
    "h_class = Dense(7, activation='softmax')(h_final_2)\n",
    "'''\n",
    "model_p1 = Model(x, h_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Aux network for \\nfrom keras.layers import Lambda, Input, Dense\\nfrom keras.models import Model\\nfrom keras import backend as K\\n\\nx = Input(shape = X_train_2.shape)\\n\\nx = Dense(500, activation='relu')(x)\\n\\nx = Dense(200,activation='relu')(x)\\n\\nx = BatchNormalization()(x)\\n\\nx = Dense(7,activaition = 'prelu')(x)\\n\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Aux network for \n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "x = Input(shape = X_train_2.shape)\n",
    "\n",
    "x = Dense(500, activation='relu')(x)\n",
    "\n",
    "x = Dense(200,activation='relu')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(7,activaition = 'prelu')(x)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "#sgd_wn = SGDWithWeightnorm(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_p1.compile(loss = categorical_crossentropy, optimizer = Adam(), metrics = ['accuracy'])\n",
    "\n",
    "# callback history \n",
    "from keras.callbacks import EarlyStopping,TensorBoard,History, ReduceLROnPlateau\n",
    "\n",
    "#earlyStop  = EarlyStopping(monitor = 'val_loss',  patience = 10)\n",
    "\n",
    "#tbcallback = TensorBoard(log_dir = './smooth_logs', histogram_freq = 0, write_graph = True, write_images = True)\n",
    "\n",
    "hist_vanilla = History()\n",
    "\n",
    "#rdLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 10, verbose = 0, \n",
    "                              #mode = 'auto', cooldown = 0, min_lr = 0)\n",
    "\n",
    "model_callbacks = [hist_vanilla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 212s - loss: 2.1082 - acc: 0.2388\n",
      "Epoch 2/150\n",
      " - 188s - loss: 1.7714 - acc: 0.2937\n",
      "Epoch 3/150\n",
      " - 185s - loss: 1.6808 - acc: 0.3358\n",
      "Epoch 4/150\n",
      " - 187s - loss: 1.6114 - acc: 0.3708\n",
      "Epoch 5/150\n",
      " - 187s - loss: 1.5543 - acc: 0.3932\n",
      "Epoch 6/150\n",
      " - 185s - loss: 1.5066 - acc: 0.4163\n",
      "Epoch 7/150\n",
      " - 192s - loss: 1.4732 - acc: 0.4323\n",
      "Epoch 8/150\n",
      " - 189s - loss: 1.4349 - acc: 0.4461\n",
      "Epoch 9/150\n",
      " - 189s - loss: 1.4134 - acc: 0.4515\n",
      "Epoch 10/150\n",
      " - 185s - loss: 1.3856 - acc: 0.4677\n",
      "Epoch 11/150\n",
      " - 206s - loss: 1.3745 - acc: 0.4709\n",
      "Epoch 12/150\n",
      " - 186s - loss: 1.3553 - acc: 0.4772\n",
      "Epoch 13/150\n",
      " - 183s - loss: 1.3339 - acc: 0.4856\n",
      "Epoch 14/150\n",
      " - 184s - loss: 1.3257 - acc: 0.4881\n",
      "Epoch 15/150\n",
      " - 189s - loss: 1.3102 - acc: 0.4964\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4da8674fa9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m           )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 150 # \n",
    "batch_size = 100\n",
    "\n",
    "model_p1.fit([X_train,X_train_2],y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs = num_epochs,\n",
    "          verbose= 2,\n",
    "          callbacks=model_callbacks,\n",
    "          shuffle=True,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
