{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "## one hot encoded labels\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train = np.load('X_train_Fer2013.npy')\n",
    "X_test = np.load('X_test_Fer2013.npy')\n",
    "y_train = np.load('y_train_Fer2013.npy')\n",
    "y_test = np.load('y_test_Fer2013.npy')\n",
    "arousal_index = np.load('pseudo_arousal.npy')\n",
    "\n",
    "import keras.backend as K\n",
    "## one hot encoded labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "### Ready for CNN shape change\n",
    "\n",
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train= X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Feeding Generated Neutral Face info.\n",
    "\n",
    "X_train_Neutral = np.load('evae_conditional_fer2013_sample_neutral_sample_neutral_a=0_v1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32298, 48, 48, 1)\n",
      "(32298, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train_Neutral.shape\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Making Binary Classification Training dataset \n",
    "### 1:x_train;   0: x_train_neutral \n",
    "\n",
    "X_train_binary = np.concatenate((X_train[:16149] ,X_train_Neutral[:16149]), axis = 0) ## shape[32298*2, 48, 48, 1]\n",
    "y_train_binary_1 = np.ones(X_train.shape[0])[:16149]\n",
    "y_train_binary_0 = np.zeros(X_train.shape[0])[:16149]\n",
    "y_train_binary  = np.concatenate((y_train_binary_1, y_train_binary_0), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32298, 48, 48, 1)\n",
      "(32298,)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print X_train_binary.shape\n",
    "print y_train_binary.shape\n",
    "print y_train_binary[16148:16150] ## checking if half is 1; and the second half is 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Tryout for making binary classification via a simple CNN net \n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32298/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, AveragePooling2D, PReLU, Dropout, Dense\n",
    "from keras.layers import Flatten, Activation,Subtract\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras import Model\n",
    "from keras.layers import Dot,Multiply,Subtract,Add,BatchNormalization, Average, Maximum\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "input_shape = (48,48,1)\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "### Network\n",
    "x_binary = Input(shape=input_shape)\n",
    "#arousal = Input(shape=(1,), name = 'fake_arousal_index')\n",
    "###  Tryout more variations of initlisation techniques \n",
    "### without any pre-training \n",
    "### without any weight initilaistion \n",
    "\n",
    "##\n",
    "h1 = Conv2D(16, (7, 7), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv1')(x_binary)\n",
    "h1 = PReLU()(h1)\n",
    "h1 = BatchNormalization()(h1)\n",
    "h1 = AveragePooling2D(pool_size=(5, 5),strides=(2, 2), padding='same')(h1)\n",
    "h1 = Dropout(.5)(h1)\n",
    "\n",
    "##\n",
    "h2 = Conv2D(32, (5, 5), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv2')(h1)\n",
    "h2 = PReLU()(h2)\n",
    "h2 = BatchNormalization()(h2)\n",
    "h2 = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h2)\n",
    "h2 = Dropout(.5)(h2)\n",
    "\n",
    "##\n",
    "h3 = Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=input_shape, name = 'block1_conv3')(h2)\n",
    "h3 = PReLU()(h3)\n",
    "h3 = BatchNormalization()(h3)\n",
    "h3 = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h3)\n",
    "h3 = Dropout(.5)(h3)\n",
    "\n",
    "\n",
    "h3 = Flatten()(h3)\n",
    "h4 = Dense(512)(h3)\n",
    "h4 = PReLU()(h4)\n",
    "h5 = Dropout(0.5)(h4)\n",
    "h5 = BatchNormalization()(h5)\n",
    "h_class = Dense(50, activation = 'relu')(h5)\n",
    "prediction_binary = Dense(1, activation='sigmoid', name = 'output_binary')(h_class)\n",
    "label_binary = Input((1,))\n",
    "#y_true = Input(shape= (7,), name = 'y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Network 2 for standard multi class\n",
    "\n",
    "input_shape = (48,48,1)\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "\n",
    "x_multi = Input(shape=input_shape)\n",
    "#arousal = Input(shape=(1,), name = 'fake_arousal_index')\n",
    "###  Tryout more variations of initlisation techniques \n",
    "### without any pre-training \n",
    "### without any weight initilaistion \n",
    "\n",
    "##\n",
    "h1_ = Conv2D(16, (7, 7), padding='same',\n",
    "                        input_shape=input_shape,)(x_multi)\n",
    "h1_ = PReLU()(h1_)\n",
    "h1_ = BatchNormalization()(h1_)\n",
    "h1_ = AveragePooling2D(pool_size=(5, 5),strides=(2, 2))(h1_)\n",
    "h1_ = Dropout(.5)(h1_)\n",
    "\n",
    "##\n",
    "h2_ = Conv2D(32, (5, 5), padding='same',\n",
    "                        input_shape=input_shape)(h1_)\n",
    "h2_ = PReLU()(h2_)\n",
    "h2_ = BatchNormalization()(h2_)\n",
    "h2_ = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h2_)\n",
    "h2_ = Dropout(.5)(h2_)\n",
    "\n",
    "##\n",
    "h3_ = Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=input_shape)(h2_)\n",
    "h3_ = PReLU()(h3_)\n",
    "h3_ = BatchNormalization()(h3_)\n",
    "h3_ = AveragePooling2D(pool_size=(3, 3),strides=(2, 2), padding='same')(h3_)\n",
    "h3_ = Dropout(.5)(h3_)\n",
    "\n",
    "\n",
    "h3_ = Flatten()(h3_)\n",
    "h4_ = Dense(512)(h3_)\n",
    "h4_ = PReLU()(h4_)\n",
    "h5_ = Dropout(0.5)(h4_)\n",
    "h5_ = BatchNormalization()(h5_)\n",
    "h_class_ = Dense(50, activation = 'relu')(h5_)\n",
    "prediction_multi = Dense(7, activation='softmax',name= 'output_multi')(h_class_)\n",
    "label_multi = Input((7,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(prediction_multi, prediction_binary, label_multi, label_binary, alpha):\n",
    "    def loss(y_true, y_pred):\n",
    "        return (1-alpha) * K.pow(categorical_crossentropy(prediction_multi, label_multi), 2) \\\n",
    "                        + alpha * K.pow(binary_crossentropy(prediction_binary, label_binary), 0.5)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping,TensorBoard,History, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy\n",
    "from keras.optimizers import Adamax, Adadelta\n",
    "\n",
    "hist_vanilla = History()\n",
    "\n",
    "#rdLR = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 10, verbose = 0, \n",
    "                              #mode = 'auto', cooldown = 0, min_lr = 0)\n",
    "\n",
    "model_callbacks = [hist_vanilla]\n",
    "\n",
    "\n",
    "losses = {\n",
    "    'output_multi':'categorical_crossentropy',\n",
    "    'output_binary': 'binary_crossentropy'\n",
    "}\n",
    "\n",
    "lossWeights = {'output_multi':1.0, 'output_binary': 1.0}\n",
    "\n",
    "\n",
    "#model_joint = Model(inputs=[x_multi, x_binary, label_multi, label_binary], outputs = [prediction_multi, prediction_binary])\n",
    "#model.add_loss(emo_loss_fixed(y_true, y_pred, arousal))\n",
    "\n",
    "#loss_joint = K.mean(K.sum(categorical_crossentropy(prediction_multi, label_multi))+\n",
    "                          #K.sum(binary_crossentropy(prediction_binary, label_binary)))\n",
    "model_joint = Model(inputs = [x_multi,x_binary], outputs = [prediction_multi, prediction_binary])\n",
    "model_joint.compile(loss= custom_loss(prediction_multi, prediction_binary, label_multi, label_binary, 0.50), \n",
    "                    optimizer = Adadelta() , metrics = ['accuracy'], target_tensors = [label_multi, label_binary])\n",
    "#model.compile(loss = None, optimizer='adam', metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_soft = np.load('proactive_label_fer2013_v6_divide12_bound2.5*7.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 334s - loss: 8.6980 - output_multi_loss: 4.3490 - output_binary_loss: 4.3490 - output_multi_acc: 0.6525 - output_binary_acc: 0.9999\n",
      "Epoch 2/50\n",
      " - 318s - loss: 8.7414 - output_multi_loss: 4.3707 - output_binary_loss: 4.3707 - output_multi_acc: 0.6544 - output_binary_acc: 0.9999\n",
      "Epoch 3/50\n",
      " - 318s - loss: 8.7530 - output_multi_loss: 4.3765 - output_binary_loss: 4.3765 - output_multi_acc: 0.6537 - output_binary_acc: 1.0000\n",
      "Epoch 4/50\n",
      " - 317s - loss: 8.7100 - output_multi_loss: 4.3550 - output_binary_loss: 4.3550 - output_multi_acc: 0.6549 - output_binary_acc: 1.0000\n",
      "Epoch 5/50\n",
      " - 317s - loss: 8.7943 - output_multi_loss: 4.3972 - output_binary_loss: 4.3972 - output_multi_acc: 0.6522 - output_binary_acc: 1.0000\n",
      "Epoch 6/50\n",
      " - 314s - loss: 8.6698 - output_multi_loss: 4.3349 - output_binary_loss: 4.3349 - output_multi_acc: 0.6565 - output_binary_acc: 1.0000\n",
      "Epoch 7/50\n",
      " - 318s - loss: 8.6707 - output_multi_loss: 4.3354 - output_binary_loss: 4.3354 - output_multi_acc: 0.6583 - output_binary_acc: 1.0000\n",
      "Epoch 8/50\n",
      " - 316s - loss: 8.7950 - output_multi_loss: 4.3975 - output_binary_loss: 4.3975 - output_multi_acc: 0.6509 - output_binary_acc: 1.0000\n",
      "Epoch 9/50\n",
      " - 316s - loss: 8.7178 - output_multi_loss: 4.3589 - output_binary_loss: 4.3589 - output_multi_acc: 0.6539 - output_binary_acc: 0.9999\n",
      "Epoch 10/50\n",
      " - 314s - loss: 8.6968 - output_multi_loss: 4.3484 - output_binary_loss: 4.3484 - output_multi_acc: 0.6537 - output_binary_acc: 1.0000\n",
      "Epoch 11/50\n",
      " - 316s - loss: 8.7447 - output_multi_loss: 4.3723 - output_binary_loss: 4.3723 - output_multi_acc: 0.6534 - output_binary_acc: 1.0000\n",
      "Epoch 12/50\n",
      " - 330s - loss: 8.6863 - output_multi_loss: 4.3431 - output_binary_loss: 4.3431 - output_multi_acc: 0.6558 - output_binary_acc: 0.9999\n",
      "Epoch 13/50\n",
      " - 353s - loss: 8.6789 - output_multi_loss: 4.3394 - output_binary_loss: 4.3394 - output_multi_acc: 0.6559 - output_binary_acc: 0.9998\n",
      "Epoch 14/50\n",
      " - 362s - loss: 8.7634 - output_multi_loss: 4.3817 - output_binary_loss: 4.3817 - output_multi_acc: 0.6543 - output_binary_acc: 0.9999\n",
      "Epoch 15/50\n",
      " - 357s - loss: 8.7297 - output_multi_loss: 4.3649 - output_binary_loss: 4.3649 - output_multi_acc: 0.6534 - output_binary_acc: 1.0000\n",
      "Epoch 16/50\n",
      " - 359s - loss: 8.6790 - output_multi_loss: 4.3395 - output_binary_loss: 4.3395 - output_multi_acc: 0.6554 - output_binary_acc: 1.0000\n",
      "Epoch 17/50\n",
      " - 363s - loss: 8.6567 - output_multi_loss: 4.3284 - output_binary_loss: 4.3284 - output_multi_acc: 0.6560 - output_binary_acc: 1.0000\n",
      "Epoch 18/50\n",
      " - 363s - loss: 8.6954 - output_multi_loss: 4.3477 - output_binary_loss: 4.3477 - output_multi_acc: 0.6541 - output_binary_acc: 1.0000\n",
      "Epoch 19/50\n",
      " - 358s - loss: 8.6342 - output_multi_loss: 4.3171 - output_binary_loss: 4.3171 - output_multi_acc: 0.6572 - output_binary_acc: 0.9999\n",
      "Epoch 20/50\n",
      " - 355s - loss: 8.6742 - output_multi_loss: 4.3371 - output_binary_loss: 4.3371 - output_multi_acc: 0.6550 - output_binary_acc: 0.9999\n",
      "Epoch 21/50\n",
      " - 359s - loss: 8.7520 - output_multi_loss: 4.3760 - output_binary_loss: 4.3760 - output_multi_acc: 0.6530 - output_binary_acc: 0.9999\n",
      "Epoch 22/50\n",
      " - 358s - loss: 8.6239 - output_multi_loss: 4.3119 - output_binary_loss: 4.3119 - output_multi_acc: 0.6566 - output_binary_acc: 0.9999\n",
      "Epoch 23/50\n",
      " - 359s - loss: 8.7127 - output_multi_loss: 4.3563 - output_binary_loss: 4.3563 - output_multi_acc: 0.6546 - output_binary_acc: 0.9999\n",
      "Epoch 24/50\n",
      " - 359s - loss: 8.6509 - output_multi_loss: 4.3254 - output_binary_loss: 4.3254 - output_multi_acc: 0.6568 - output_binary_acc: 1.0000\n",
      "Epoch 25/50\n",
      " - 361s - loss: 8.6928 - output_multi_loss: 4.3464 - output_binary_loss: 4.3464 - output_multi_acc: 0.6542 - output_binary_acc: 1.0000\n",
      "Epoch 26/50\n",
      " - 360s - loss: 8.6044 - output_multi_loss: 4.3022 - output_binary_loss: 4.3022 - output_multi_acc: 0.6564 - output_binary_acc: 1.0000\n",
      "Epoch 27/50\n",
      " - 359s - loss: 8.6412 - output_multi_loss: 4.3206 - output_binary_loss: 4.3206 - output_multi_acc: 0.6573 - output_binary_acc: 1.0000\n",
      "Epoch 28/50\n",
      " - 358s - loss: 8.6507 - output_multi_loss: 4.3254 - output_binary_loss: 4.3254 - output_multi_acc: 0.6566 - output_binary_acc: 1.0000\n",
      "Epoch 29/50\n",
      " - 358s - loss: 8.6183 - output_multi_loss: 4.3092 - output_binary_loss: 4.3092 - output_multi_acc: 0.6551 - output_binary_acc: 0.9998\n",
      "Epoch 30/50\n",
      " - 358s - loss: 8.6742 - output_multi_loss: 4.3371 - output_binary_loss: 4.3371 - output_multi_acc: 0.6535 - output_binary_acc: 0.9999\n",
      "Epoch 31/50\n",
      " - 359s - loss: 8.6728 - output_multi_loss: 4.3364 - output_binary_loss: 4.3364 - output_multi_acc: 0.6547 - output_binary_acc: 1.0000\n",
      "Epoch 32/50\n",
      " - 357s - loss: 8.6388 - output_multi_loss: 4.3194 - output_binary_loss: 4.3194 - output_multi_acc: 0.6580 - output_binary_acc: 1.0000\n",
      "Epoch 33/50\n",
      " - 360s - loss: 8.6088 - output_multi_loss: 4.3044 - output_binary_loss: 4.3044 - output_multi_acc: 0.6571 - output_binary_acc: 1.0000\n",
      "Epoch 34/50\n",
      " - 357s - loss: 8.6743 - output_multi_loss: 4.3371 - output_binary_loss: 4.3371 - output_multi_acc: 0.6568 - output_binary_acc: 1.0000\n",
      "Epoch 35/50\n",
      " - 360s - loss: 8.6426 - output_multi_loss: 4.3213 - output_binary_loss: 4.3213 - output_multi_acc: 0.6564 - output_binary_acc: 0.9999\n",
      "Epoch 36/50\n",
      " - 360s - loss: 8.6760 - output_multi_loss: 4.3380 - output_binary_loss: 4.3380 - output_multi_acc: 0.6558 - output_binary_acc: 1.0000\n",
      "Epoch 37/50\n",
      " - 359s - loss: 8.5987 - output_multi_loss: 4.2993 - output_binary_loss: 4.2993 - output_multi_acc: 0.6582 - output_binary_acc: 1.0000\n",
      "Epoch 38/50\n",
      " - 359s - loss: 8.5452 - output_multi_loss: 4.2726 - output_binary_loss: 4.2726 - output_multi_acc: 0.6589 - output_binary_acc: 1.0000\n",
      "Epoch 39/50\n",
      " - 360s - loss: 8.5817 - output_multi_loss: 4.2909 - output_binary_loss: 4.2909 - output_multi_acc: 0.6584 - output_binary_acc: 1.0000\n",
      "Epoch 40/50\n",
      " - 360s - loss: 8.6180 - output_multi_loss: 4.3090 - output_binary_loss: 4.3090 - output_multi_acc: 0.6573 - output_binary_acc: 0.9999\n",
      "Epoch 41/50\n",
      " - 360s - loss: 8.6758 - output_multi_loss: 4.3379 - output_binary_loss: 4.3379 - output_multi_acc: 0.6578 - output_binary_acc: 1.0000\n",
      "Epoch 42/50\n",
      " - 356s - loss: 8.6265 - output_multi_loss: 4.3132 - output_binary_loss: 4.3132 - output_multi_acc: 0.6572 - output_binary_acc: 1.0000\n",
      "Epoch 43/50\n",
      " - 362s - loss: 8.5472 - output_multi_loss: 4.2736 - output_binary_loss: 4.2736 - output_multi_acc: 0.6600 - output_binary_acc: 1.0000\n",
      "Epoch 44/50\n",
      " - 360s - loss: 8.6407 - output_multi_loss: 4.3203 - output_binary_loss: 4.3203 - output_multi_acc: 0.6576 - output_binary_acc: 0.9999\n",
      "Epoch 45/50\n",
      " - 359s - loss: 8.6266 - output_multi_loss: 4.3133 - output_binary_loss: 4.3133 - output_multi_acc: 0.6572 - output_binary_acc: 0.9999\n",
      "Epoch 46/50\n",
      " - 359s - loss: 8.5536 - output_multi_loss: 4.2768 - output_binary_loss: 4.2768 - output_multi_acc: 0.6592 - output_binary_acc: 1.0000\n",
      "Epoch 47/50\n",
      " - 361s - loss: 8.6592 - output_multi_loss: 4.3296 - output_binary_loss: 4.3296 - output_multi_acc: 0.6570 - output_binary_acc: 1.0000\n",
      "Epoch 48/50\n",
      " - 361s - loss: 8.6635 - output_multi_loss: 4.3318 - output_binary_loss: 4.3318 - output_multi_acc: 0.6562 - output_binary_acc: 1.0000\n",
      "Epoch 49/50\n",
      " - 358s - loss: 8.6818 - output_multi_loss: 4.3409 - output_binary_loss: 4.3409 - output_multi_acc: 0.6559 - output_binary_acc: 1.0000\n",
      "Epoch 50/50\n",
      " - 357s - loss: 8.5425 - output_multi_loss: 4.2712 - output_binary_loss: 4.2712 - output_multi_acc: 0.6609 - output_binary_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x109db2f10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50 # \n",
    "batch_size = 100\n",
    "\n",
    "model_joint.fit([X_train, X_train_binary],[y_train_soft, y_train_binary], \n",
    "          batch_size = batch_size,\n",
    "          epochs = num_epochs,\n",
    "          verbose= 2,\n",
    "          callbacks=model_callbacks,\n",
    "          shuffle=True,\n",
    "          ) ## works but overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "####\n",
    "import pandas as pd\n",
    "\n",
    "#vanilla_cnn_fer2013 = hist_vanilla.history\n",
    "\n",
    "#pd.DataFrame(vanilla_cnn_fer2013).to_csv('emo-focal_dualNet_softlabel_last50ep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_binary_ = X_train_binary[:3589]\n",
    "y_train_binary_ = y_train_binary[:3589]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 19s 5ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "\n",
    "score = model_joint.evaluate([X_test, X_train_binary_], [y_test, y_train_binary_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87.46136066461214,\n",
       " 43.73068033230607,\n",
       " 43.73068033230607,\n",
       " 0.6168849261715805,\n",
       " 1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
